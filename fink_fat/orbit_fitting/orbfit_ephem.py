import os
import pandas as pd
import numpy as np
import multiprocessing as mp
import shutil

import traceback
import logging


import fink_fat.orbit_fitting.orbfit_files as of
import fink_fat.orbit_fitting.mpcobs_files as mf
import fink_fat.orbit_fitting.orbfit_local as ol


def cache_orbit(traj_id, cache_path):
    """
    Cache the .oel file into the cache_path folder to avoid the orbit fitting for the ephemeries.

    Parameters
    ----------
    traj_id : integer
        the trajectories identifier
    cache_path : string
        the cache folder where will be stored the .oel file, must finish with a '/'.

    Returns
    -------
    init_orbit : string
        the .oel file path in the cache folder

    Examples
    --------

    >>> cache_orbit(0, "cache_folder/")

    >>> os.rmdir("cache_folder")

    >>> os.mkdir("cache_folder")
    >>> open("cache_folder/orbit_0.oel", 'w').close()
    >>> cache_orbit(0, "cache_folder/")
    'cache_folder/orbit_0.oel'
    >>> shutil.rmtree("cache_folder")
    """
    # cache the orbital element file (.oel) into the cache_path location.
    init_orbit = None
    if cache_path is not None:
        if os.path.exists(cache_path):
            orbit_path = os.path.join(cache_path, "orbit_{}.oel".format(traj_id))
            if os.path.exists(orbit_path):
                init_orbit = orbit_path
        else:
            # create the cache folder if not exists.
            os.mkdir(cache_path)

    return init_orbit


def trajectory_ephemeris(
    observation,
    traj_id,
    ram_dir,
    start_ephem,
    end_ephem=None,
    dt_ephem=None,
    obs_code=675,
    prop_epoch=None,
    n_triplets=10,
    noise_ntrials=10,
    verbose=1,
    cache_path=None,
):
    """
    Compute the ephemeris of one trajectory. Can recompute the orbit or read an existing orbit file (.oel).

    Parameters
    ----------
    observation : DataFrame
        observation of solar system objects
        column description:
            ra: right ascension
            dec: declination
            fid: filter id
            jd: julian date
            trajectory_id: trajectory identifier
    traj_id : integer
        trajectory identifier, must be in the trajectory_id column of the observation dataframe
    ram_dir : string
        the path where to write the temporary file generated by orbfit.
    start_ephem : string
        start date to compute the ephemeris, same format as the prop_epoch keyword.
    end_epehm : string
        start date to compute the ephemeris.
    dt_ephem : float
        Ephemeris stepsize in days
    obscode : integer
        Observatory code for which ephemeris has to be computed, required for applying topocentric correction.
        Observatory codes can be found here : https://en.wikipedia.org/wiki/List_of_observatory_codes
        Take only the observatory code before 999 (those without letters).
    prop_epoch : string
        Epoch at which output orbital elements
        Epochs can be specified in Julian Days, Modified Julian Days or
        calendar date/time, according to the following examples
        prop_epoch     = CAL 1998/Jun/18 22:35:40.00 UTC
            or         = CAL 1998/06/18  22:35:40.00 UTC
            or         = JD  2450983.44143519 UTC
            or         = MJD 50982.94143519 UTC ! MJD with fractional part
            or         = MJD 50982 81340.00 UTC ! integer MJD & secs within day)
    n_triplets : integer
        max number of triplets of observations to be tried for the initial orbit determination
    noise_ntrials : integer
        number of trials for each triplet for the initial orbit determination
    verbose : integer
        Verbosity levels of Orbfit
        1 = summary information on the solution found
        2 = summary information on all trials
        3 = debug
    cache_orbit : string
        the cache folder where will be stored the .oel file, must finish with a '/'.

    Returns
    -------
    res_ephem : dataframe
        ephemeris of the trajectory corresponding to the traj_id.
        columns description:
            jd:                ephem date in JD2000 (day)
            ra:                ephemeris right ascension (degree)
            dec:               ephemeris declination (degree)
            mag:               ephemeris magnitude
            delta_(AU):        distance from the Earth (Astronomical units)
            R_(AU):            distance from the Sun (Astronomical units)
            SolEl_(degree):    Sun elongation angle (degree)
            Phase_(degree):    Sun phase angle (degree)
            Glat_(degree):     galactic latitude (degree)
            ra*cosDec_(deg/d): apparent motion (degree/day)
            dec_(deg/d):       apparent motion (degree/day)
            Vel_(deg/d):       Velocity (degree/day)
            Err1_(arcsec):     sky plane error (arcsecond)
            Err2_(arcsec):     sky plane error (arcsecond)
    res_orbit : dataframe
        the orbit of the solar system object used to compute the ephemeris
        column description:
            ref_epoch: referent epoch of the orbit (Julian date)
            a: semi-major axis (Astronomical unit)
            e: eccentricity
            i: inclination
            long. node: longitude of the ascending node (degree)
            arg. peri: argument of periapsis (degree)
            mean anomaly: (degree)

    Examples
    --------
    >>> ram_dir = "fink_fat/test/ephem_test/"
    >>> df_traj = pd.read_parquet("fink_fat/test/ephem_test/ephem_traj.parquet")
    >>> start_ephem = 2459732.43750
    >>> end_ephem = 2459761.43750

    >>> of.prep_orbitfit(ram_dir)

    >>> res_ephem, res_orb = trajectory_ephemeris(df_traj, 5, ram_dir, start_ephem = start_ephem, end_ephem = end_ephem, prop_epoch = df_traj["jd"].values[0], cache_path=None, n_triplets=30, noise_ntrials=20)
    >>> res_ephem_test = pd.read_parquet("fink_fat/test/ephem_test/res_ephem.parquet")
    >>> res_orb_test = pd.read_parquet("fink_fat/test/ephem_test/res_orb.parquet")
    >>> res_orb_test["trajectory_id"] = 5

    >>> assert_frame_equal(res_ephem_test, res_ephem)
    >>> assert_frame_equal(res_orb_test, res_orb)

    >>> res_ephem, res_orb = trajectory_ephemeris(df_traj, 5, ram_dir, start_ephem = start_ephem, cache_path=ram_dir + "cache_orb/", n_triplets=30, noise_ntrials=20)
    >>> res_ephem_test = pd.read_parquet("fink_fat/test/ephem_test/res_ephem2.parquet")
    >>> res_orb_test = pd.read_parquet("fink_fat/test/ephem_test/res_orb2.parquet")
    >>> res_orb_test["trajectory_id"] = 5

    >>> assert_frame_equal(res_ephem_test, res_ephem)
    >>> assert_frame_equal(res_orb_test, res_orb)

    >>> of.final_clean(ram_dir)
    >>> os.rmdir(ram_dir + "mpcobs")
    >>> shutil.rmtree(ram_dir + "cache_orb/")
    """
    df_one_traj = observation[observation["trajectory_id"] == traj_id]
    prov_desig = mf.write_observation_file(ram_dir, df_one_traj)
    of.write_inp(ram_dir, prov_desig)

    if end_ephem is None:
        end_ephem = start_ephem

    init_orbit = cache_orbit(traj_id, cache_path)

    if prop_epoch is None:
        of.write_oop(
            ram_dir,
            prov_desig,
            prop_epoch="JD  {} UTC".format(df_one_traj["jd"].values[-1]),
            n_triplets=n_triplets,
            noise_ntrials=noise_ntrials,
            verbose=verbose,
            with_ephem=2,
            start_ephem="JD  {} UTC".format(start_ephem),
            end_ephem="JD  {} UTC".format(end_ephem),
            step_ephem=dt_ephem,
            obscode=obs_code,
            init_orb_file=init_orbit,
        )
    else:
        of.write_oop(
            ram_dir,
            prov_desig,
            prop_epoch="JD  {} UTC".format(prop_epoch),
            n_triplets=n_triplets,
            noise_ntrials=noise_ntrials,
            verbose=verbose,
            with_ephem=2,
            start_ephem="JD  {} UTC".format(start_ephem),
            end_ephem="JD  {} UTC".format(end_ephem),
            step_ephem=dt_ephem,
            obscode=obs_code,
            init_orb_file=init_orbit,
        )

    try:
        ol.call_orbitfit(ram_dir, prov_desig)
    except Exception as e:  # pragma: no cover
        print(e)
        print("ERROR CALLING ORBFIT: {}".format(prov_desig))
        print()
        logging.error(traceback.format_exc())
        print()
        print(prov_desig)
        print()
        print()
        print(df_one_traj)

    res_ephem = of.read_ephem(ram_dir, prov_desig)

    res_orbit = of.read_oel(ram_dir, prov_desig)

    res_ephem["trajectory_id"] = traj_id

    if cache_path is not None:
        # move the .oel file into the cache folder
        if (
            not os.path.exists(cache_path + "orbit_{}.oel".format(traj_id))
        ) and os.path.exists(ram_dir + prov_desig + ".oel"):
            shutil.move(
                ram_dir + prov_desig + ".oel",
                cache_path + "orbit_{}.oel".format(traj_id),
            )

    try:
        of.obs_clean(ram_dir, prov_desig)
    except FileNotFoundError:  # pragma: no cover
        print("ERROR CLEANING ORBFIT: {}".format(prov_desig))
        print(prov_desig)
        print()
        print()
        print(df_one_traj)

    orb_columns = [
        "ref_epoch",
        "a",
        "e",
        "i",
        "long. node",
        "arg. peric",
        "mean anomaly",
        "rms_a",
        "rms_e",
        "rms_i",
        "rms_long. node",
        "rms_arg. peric",
        "rms_mean anomaly",
    ]

    res_orbit = pd.DataFrame([res_orbit], columns=orb_columns)
    res_orbit["trajectory_id"] = traj_id
    res_orbit = res_orbit.apply(pd.to_numeric)
    return res_ephem, res_orbit


def aux_ephem(
    observation,
    chunk,
    ram_dir,
    start_ephem,
    end_ephem=None,
    dt_ephem=None,
    obs_code=675,
    prop_epoch=None,
    n_triplets=10,
    noise_ntrials=10,
    verbose=1,
    cache_path=None,
):
    """
    Auxiliary ephemeris function that compute ephemeris for a set of trajectory.

    Parameters:
    -----------
    observation : DataFrame
        the trajectories observations
    chunk: integer list
        the trajectories identifiers to compute the ephemeries.
    ram_dir : string
        the path where to write the temporary file generated by orbfit.
    start_ephem : string
        start date to compute the ephemeris, same format as the prop_epoch keyword.
    end_epehm : string
        start date to compute the ephemeris.
    step_ephem : float
        Ephemeris stepsize in days
    obscode : integer
        Observatory code for which ephemeris has to be computed, required for applying topocentric correction.
        Observatory codes can be found here : https://en.wikipedia.org/wiki/List_of_observatory_codes
        Take only the observatory code before 999 (those without letters).
    prop_epoch : string
        Epoch at which output orbital elements
        Epochs can be specified in Julian Days, Modified Julian Days or
        calendar date/time, according to the following examples
        prop_epoch     = CAL 1998/Jun/18 22:35:40.00 UTC
            or         = CAL 1998/06/18  22:35:40.00 UTC
            or         = JD  2450983.44143519 UTC
            or         = MJD 50982.94143519 UTC ! MJD with fractional part
            or         = MJD 50982 81340.00 UTC ! integer MJD & secs within day)
    n_triplets : integer
        max number of triplets of observations to be tried for the initial orbit determination
    noise_ntrials : integer
        number of trials for each triplet for the initial orbit determination
    verbose : integer
        Verbosity levels of Orbfit
        1 = summary information on the solution found
        2 = summary information on all trials
        3 = debug
    cache_path : string
        the cache_path where to save the .oel files generates by OrbFit.

    Returns
    -------
    ephem_data : DataFrame
        a dataframe containing ephemeries for each trajectories in chunk.

    Examples
    --------
    >>> ram_dir = "fink_fat/test/ephem_test/"
    >>> df_traj = pd.read_parquet("fink_fat/test/ephem_test/ephem_multiple_traj.parquet")
    >>> start_ephem = 2459732.43750
    >>> end_ephem = 2459761.43750

    >>> of.prep_orbitfit(ram_dir)

    >>> res_ephem, res_orb = aux_ephem(df_traj, [1, 3, 5], ram_dir, start_ephem = start_ephem, end_ephem=end_ephem, cache_path=None, n_triplets=30, noise_ntrials=20)

    >>> res_ephem_test = pd.read_parquet("fink_fat/test/ephem_test/res_multiple_ephem.parquet")
    >>> res_orb_test = pd.read_parquet("fink_fat/test/ephem_test/res_multiple_orb.parquet")

    >>> assert_frame_equal(res_ephem_test, res_ephem)
    >>> assert_frame_equal(res_orb_test, res_orb)

    >>> of.final_clean(ram_dir)
    >>> os.rmdir(ram_dir + "mpcobs")
    """
    res_ephem = []
    res_orb = []
    for tr_id in chunk:
        ephem, orb = trajectory_ephemeris(
            observation,
            tr_id,
            ram_dir,
            start_ephem,
            end_ephem,
            dt_ephem,
            obs_code,
            prop_epoch,
            n_triplets,
            noise_ntrials,
            verbose,
            cache_path,
        )
        res_ephem.append(ephem)
        res_orb.append(orb)
    return pd.concat(res_ephem), pd.concat(res_orb)


def parallel_ephem(
    observation,
    ram_dir,
    cpu_count,
    start_ephem,
    end_ephem=None,
    dt_ephem=None,
    obs_code=500,
    prop_epoch=None,
    n_triplets=10,
    noise_ntrials=10,
    verbose=1,
    cache_path=None,
):
    """
     Compute ephemeris for a set of trajectory in parallel.

    Parameters:
    -----------
    observation : DataFrame
        the trajectories observations
    ram_dir : string
        the path where to write the temporary file generated by orbfit.
    cpu_count : integer
        the number of core for the parallel computation
    start_ephem : string
        start date to compute the ephemeris, same format as the prop_epoch keyword.
    end_epehm : string
        start date to compute the ephemeris.
    step_ephem : float
        Ephemeris stepsize in days
    obscode : integer
        Observatory code for which ephemeris has to be computed, required for applying topocentric correction.
        Observatory codes can be found here : https://en.wikipedia.org/wiki/List_of_observatory_codes
        Take only the observatory code before 999 (those without letters).
    prop_epoch : string
        Epoch at which output orbital elements
        Epochs can be specified in Julian Days, Modified Julian Days or
        calendar date/time, according to the following examples
        prop_epoch     = CAL 1998/Jun/18 22:35:40.00 UTC
            or         = CAL 1998/06/18  22:35:40.00 UTC
            or         = JD  2450983.44143519 UTC
            or         = MJD 50982.94143519 UTC ! MJD with fractional part
            or         = MJD 50982 81340.00 UTC ! integer MJD & secs within day)
    n_triplets : integer
        max number of triplets of observations to be tried for the initial orbit determination
    noise_ntrials : integer
        number of trials for each triplet for the initial orbit determination
    verbose : integer
        Verbosity levels of Orbfit
        1 = summary information on the solution found
        2 = summary information on all trials
        3 = debug
    cache_path : string
        the cache_path where to save the .oel files generates by OrbFit. Must finish with a '/'.

    Returns
    -------
    ephem_data : DataFrame
        a dataframe containing ephemeries for each trajectories in chunk.

    Examples
    --------
    >>> ram_dir = "fink_fat/test/ephem_test/"
    >>> df_traj = pd.read_parquet("fink_fat/test/ephem_test/ephem_multiple_traj.parquet")
    >>> start_ephem = 2459732.43750
    >>> end_ephem = 2459761.43750

    >>> res_ephem, res_orb = parallel_ephem(
    ... df_traj,
    ... ram_dir,
    ... 3,
    ... start_ephem = start_ephem,
    ... end_ephem=end_ephem,
    ... cache_path=None,
    ... n_triplets=30,
    ... noise_ntrials=20
    ... )

    >>> res_ephem_test = pd.read_parquet("fink_fat/test/ephem_test/res_parallel_ephem.parquet")
    >>> res_orb_test = pd.read_parquet("fink_fat/test/ephem_test/res_parallel_orb.parquet")

    >>> assert_frame_equal(res_ephem_test, res_ephem)
    >>> assert_frame_equal(res_orb_test, res_orb)
    """

    all_traj_id = np.unique(observation["trajectory_id"].values)

    trajectory_id_chunks = np.array_split(all_traj_id, cpu_count)

    chunk_ramdir = [
        os.path.join(ram_dir, "chunkid_{}".format(chunk_id), "")
        for chunk_id in np.arange(len(trajectory_id_chunks))
    ]

    for chunk_dir in chunk_ramdir:
        os.mkdir(chunk_dir)
        of.prep_orbitfit(chunk_dir)

    chunks = [
        (
            observation[observation["trajectory_id"].isin(tr_chunk)],
            tr_chunk,
            chunk_dir,
            start_ephem,
            end_ephem,
            dt_ephem,
            obs_code,
            prop_epoch,
            n_triplets,
            noise_ntrials,
            verbose,
            cache_path,
        )
        for tr_chunk, chunk_dir in zip(trajectory_id_chunks, chunk_ramdir)
        if len(tr_chunk) > 0
    ]

    pool = mp.Pool(cpu_count)

    res_parallel = pool.starmap(aux_ephem, chunks)
    res_ephem, res_orb = [], []
    for ephem, orb in res_parallel:
        res_ephem.append(ephem)
        res_orb.append(orb)

    res_ephem, res_orb = pd.concat(res_ephem), pd.concat(res_orb)

    pool.close()

    for chunk_dir in chunk_ramdir:
        shutil.rmtree(chunk_dir)

    of.final_clean(ram_dir)

    return res_ephem, res_orb


if __name__ == "__main__":  # pragma: no cover
    import sys
    import doctest
    from pandas.testing import assert_frame_equal  # noqa: F401
    import fink_fat.test.test_sample as ts  # noqa: F401
    from unittest import TestCase  # noqa: F401
    import filecmp  # noqa: F401
    import stat  # noqa: F401

    if "unittest.util" in __import__("sys").modules:
        # Show full diff in self.assertEqual.
        __import__("sys").modules["unittest.util"]._MAX_LENGTH = 999999999

    sys.exit(doctest.testmod()[0])
